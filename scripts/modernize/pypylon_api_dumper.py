#!/usr/bin/env python3
"""
PyPylon API Dumper

Extracts comprehensive API information from pypylon and saves it to JSON format.
This creates a complete snapshot of the public API for compatibility checking.

Usage:
    python pypylon_api_dumper.py --output pypylon_api_v4.2.0.json
    python pypylon_api_dumper.py --python-env /path/to/venv/bin/python --output pypylon_local.json
"""

import argparse
import json
import subprocess
import sys
import inspect
import types
import warnings
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Set
import hashlib
from datetime import datetime
import os


class PylonAPIExtractor:
    """Extracts comprehensive API information from pypylon modules"""
    
    def __init__(self, python_executable: str = None):
        self.python_executable = python_executable or sys.executable
    
    def extract_api(self) -> Dict[str, Any]:
        """Extract complete API information from pypylon"""
        
        # Create extraction script
        script = self._generate_extraction_script()
        
        # Set environment for camera emulation
        env = os.environ.copy()
        env["PYLON_CAMEMU"] = "1"
        
        # Run extraction in target environment
        print(f"üîç Running extraction subprocess...")
        print(f"   Python: {self.python_executable}")
        print(f"   Environment: PYLON_CAMEMU={env.get('PYLON_CAMEMU', 'not set')}")
        
        result = subprocess.run(
            [self.python_executable, "-c", script],
            capture_output=True,
            text=True,
            env=env,
            timeout=300  # 5 minute timeout
        )
        
        print(f"   Return code: {result.returncode}")
        print(f"   STDERR length: {len(result.stderr)}")
        print(f"   STDOUT length: {len(result.stdout)}")
        
        # Show stderr if there's any
        if result.stderr:
            print("üìã STDERR output:")
            for i, line in enumerate(result.stderr.splitlines()[:20]):  # First 20 lines
                print(f"   {i+1:2d}: {line}")
            if len(result.stderr.splitlines()) > 20:
                print(f"   ... and {len(result.stderr.splitlines()) - 20} more lines")
        
        if result.returncode != 0:
            print("‚ùå Subprocess failed!")
            if result.stdout:
                print("üìã STDOUT output:")
                for i, line in enumerate(result.stdout.splitlines()[:10]):
                    print(f"   {i+1:2d}: {line}")
            raise RuntimeError(f"API extraction subprocess failed with code {result.returncode}\nSTDERR: {result.stderr[:1000]}\nSTDOUT: {result.stdout[:1000]}")
        
        # Try to parse JSON output
        if not result.stdout.strip():
            raise RuntimeError("No output from extraction subprocess")
        
        try:
            # Show first few lines of stdout for debugging
            stdout_lines = result.stdout.splitlines()
            print(f"üìã STDOUT preview (first 5 lines):")
            for i, line in enumerate(stdout_lines[:5]):
                print(f"   {i+1:2d}: {line[:100]}{'...' if len(line) > 100 else ''}")
            
            return json.loads(result.stdout)
        except json.JSONDecodeError as e:
            print("‚ùå JSON parsing failed!")
            print(f"   Error: {e}")
            print(f"   Position: {e.pos if hasattr(e, 'pos') else 'unknown'}")
            # Show the problematic part of the output
            stdout_preview = result.stdout[:2000] if len(result.stdout) > 2000 else result.stdout
            print(f"üìã Raw output preview:\n{stdout_preview}")
            raise RuntimeError(f"Failed to parse JSON from subprocess output: {e}\nFirst 1000 chars: {result.stdout[:1000]}")
    
    def _generate_extraction_script(self) -> str:
        """Generate Python script for comprehensive API extraction"""
        return '''
import sys
import inspect
import json
import types
import warnings
import platform
import os
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
import traceback

# Suppress warnings during introspection
warnings.filterwarnings("ignore")

def safe_getattr(obj, name, default=None):
    """Safely get attribute, handling access errors"""
    try:
        return getattr(obj, name, default)
    except Exception:
        return default

def safe_str(obj, max_length=500):
    """Safely convert object to string with length limit"""
    try:
        s = str(obj)
        if len(s) > max_length:
            return s[:max_length] + "..."
        return s
    except Exception:
        return "<repr_error>"

def safe_repr(obj, max_length=200):
    """Safely get repr of object"""
    try:
        r = repr(obj)
        if len(r) > max_length:
            return r[:max_length] + "..."
        return r
    except Exception:
        return "<repr_error>"

def get_signature_info(func):
    """Extract comprehensive function signature information"""
    try:
        sig = inspect.signature(func)
        
        params = {}
        for name, param in sig.parameters.items():
            param_info = {
                "name": name,
                "kind": param.kind.name,
                "has_default": param.default != param.empty,
                "default_value": safe_str(param.default) if param.default != param.empty else None,
                "default_repr": safe_repr(param.default) if param.default != param.empty else None,
                "has_annotation": param.annotation != param.empty,
                "annotation": safe_str(param.annotation) if param.annotation != param.empty else None
            }
            params[name] = param_info
        
        return {
            "signature_str": str(sig),
            "parameters": params,
            "parameter_count": len(sig.parameters),
            "has_return_annotation": sig.return_annotation != sig.empty,
            "return_annotation": safe_str(sig.return_annotation) if sig.return_annotation != sig.empty else None,
            "callable": True
        }
    except Exception as e:
        return {
            "signature_str": "unavailable",
            "error": str(e),
            "callable": callable(func)
        }

def analyze_function(func, name=None):
    """Analyze a function or method comprehensively"""
    if name is None:
        name = safe_getattr(func, "__name__", "unknown")
    
    info = {
        "name": name,
        "type": "function",
        "doc": safe_getattr(func, "__doc__"),
        "module": safe_getattr(func, "__module__"),
        "qualname": safe_getattr(func, "__qualname__"),
        "file": safe_getattr(safe_getattr(func, "__code__"), "co_filename") if hasattr(func, "__code__") else None,
        "lineno": safe_getattr(safe_getattr(func, "__code__"), "co_firstlineno") if hasattr(func, "__code__") else None,
        "is_builtin": inspect.isbuiltin(func),
        "is_method": inspect.ismethod(func),
        "is_function": inspect.isfunction(func),
        "is_coroutine": inspect.iscoroutinefunction(func),
        "is_generator": inspect.isgeneratorfunction(func),
        "is_async_generator": inspect.isasyncgenfunction(func),
    }
    
    # Add comprehensive signature information
    info.update(get_signature_info(func))
    
    # Add docstring analysis
    if info["doc"]:
        info["doc_length"] = len(info["doc"])
        info["doc_lines"] = info["doc"].count('\\n') + 1
        info["has_parameters_doc"] = "Parameters" in info["doc"] or "Args:" in info["doc"]
        info["has_returns_doc"] = "Returns" in info["doc"] or "Return:" in info["doc"]
        info["has_examples_doc"] = "Example" in info["doc"]
    else:
        info["doc_length"] = 0
        info["doc_lines"] = 0
        info["has_parameters_doc"] = False
        info["has_returns_doc"] = False
        info["has_examples_doc"] = False
    
    return info

def analyze_property(prop, name):
    """Analyze a property"""
    return {
        "name": name,
        "type": "property",
        "doc": safe_getattr(prop, "__doc__"),
        "has_getter": prop.fget is not None,
        "has_setter": prop.fset is not None,
        "has_deleter": prop.fdel is not None,
        "getter_doc": safe_getattr(prop.fget, "__doc__") if prop.fget else None,
        "setter_doc": safe_getattr(prop.fset, "__doc__") if prop.fset else None,
        "deleter_doc": safe_getattr(prop.fdel, "__doc__") if prop.fdel else None
    }

def analyze_class(cls, name=None):
    """Analyze a class and all its members comprehensively"""
    if name is None:
        name = safe_getattr(cls, "__name__", "unknown")
    
    info = {
        "name": name,
        "type": "class",
        "doc": safe_getattr(cls, "__doc__"),
        "module": safe_getattr(cls, "__module__"),
        "qualname": safe_getattr(cls, "__qualname__"),
        "file": safe_getattr(cls, "__file__", None),
        "bases": [safe_getattr(base, "__name__", str(base)) for base in safe_getattr(cls, "__bases__", [])],
        "mro": [safe_getattr(c, "__name__", str(c)) for c in safe_getattr(cls, "__mro__", [])],
        "is_abstract": inspect.isabstract(cls),
        "methods": {},
        "properties": {},
        "class_attributes": {},
        "static_methods": {},
        "class_methods": {},
        "special_methods": {},
        "nested_classes": {}
    }
    
    # Add docstring analysis
    if info["doc"]:
        info["doc_length"] = len(info["doc"])
        info["doc_lines"] = info["doc"].count('\\n') + 1
    else:
        info["doc_length"] = 0
        info["doc_lines"] = 0
    
    # Get all attributes including inherited ones
    all_attrs = set()
    try:
        all_attrs.update(dir(cls))
    except Exception as e:
        print(f"Warning: Could not get dir() for class {name}: {e}", file=sys.stderr)
        return info  # Return early if we can't even get the directory
    
    # Analyze each attribute
    for attr_name in all_attrs:
        try:
            attr = getattr(cls, attr_name)
            
            # Categorize the attribute
            if attr_name.startswith("__") and attr_name.endswith("__"):
                # Special methods
                if callable(attr):
                    info["special_methods"][attr_name] = analyze_function(attr, attr_name)
            elif inspect.ismethod(attr):
                info["methods"][attr_name] = analyze_function(attr, attr_name)
            elif inspect.isfunction(attr):
                if hasattr(attr, "__self__") and attr.__self__ is cls:
                    info["class_methods"][attr_name] = analyze_function(attr, attr_name)
                else:
                    info["methods"][attr_name] = analyze_function(attr, attr_name)
            elif isinstance(attr, staticmethod):
                info["static_methods"][attr_name] = analyze_function(attr.__func__, attr_name)
            elif isinstance(attr, classmethod):
                info["class_methods"][attr_name] = analyze_function(attr.__func__, attr_name)
            elif isinstance(attr, property):
                info["properties"][attr_name] = analyze_property(attr, attr_name)
            elif inspect.isclass(attr):
                # Nested class
                info["nested_classes"][attr_name] = analyze_class(attr, attr_name)
            else:
                # Class attribute/constant
                info["class_attributes"][attr_name] = {
                    "name": attr_name,
                    "type": type(attr).__name__,
                    "value": safe_str(attr, 100),
                    "repr": safe_repr(attr, 100),
                    "is_callable": callable(attr),
                    "value_type": str(type(attr))
                }
        except Exception as e:
            # Record inaccessible attributes
            info["class_attributes"][attr_name] = {
                "name": attr_name,
                "type": "inaccessible",
                "error": str(e),
                "is_callable": False
            }
    
    # Add summary statistics
    info["stats"] = {
        "total_methods": len(info["methods"]),
        "total_properties": len(info["properties"]),
        "total_class_attributes": len(info["class_attributes"]),
        "total_static_methods": len(info["static_methods"]),
        "total_class_methods": len(info["class_methods"]),
        "total_special_methods": len(info["special_methods"]),
        "total_nested_classes": len(info["nested_classes"]),
        "inheritance_depth": len(info["mro"]) - 1  # -1 to exclude the class itself
    }
    
    return info

def analyze_module(module, name=None, depth=0, max_depth=3):
    """Analyze a module and its contents comprehensively"""
    if name is None:
        name = safe_getattr(module, "__name__", "unknown")
    
    print(f"üì¶ Analyzing module: {name} (depth {depth})", file=sys.stderr)
    
    if depth > max_depth:
        print(f"‚ö†Ô∏è  Module {name} too deep (depth {depth} > {max_depth})", file=sys.stderr)
        return {
            "name": name,
            "type": "module_too_deep",
            "depth_exceeded": True
        }
    
    info = {
        "name": name,
        "type": "module",
        "doc": safe_getattr(module, "__doc__"),
        "file": safe_getattr(module, "__file__"),
        "package": safe_getattr(module, "__package__"),
        "version": safe_getattr(module, "__version__", "unknown"),
        "all": safe_getattr(module, "__all__", None),
        "loader": str(safe_getattr(module, "__loader__", None)),
        "spec": str(safe_getattr(module, "__spec__", None)),
        "classes": {},
        "functions": {},
        "constants": {},
        "submodules": {},
        "exceptions": {},
        "variables": {}
    }
    
    # Add docstring analysis
    if info["doc"]:
        info["doc_length"] = len(info["doc"])
        info["doc_lines"] = info["doc"].count('\\n') + 1
    else:
        info["doc_length"] = 0
        info["doc_lines"] = 0
    
    # Get all public attributes (respect __all__ if it exists)
    if info["all"] is not None:
        public_attrs = info["all"]
    else:
        try:
            all_attrs = dir(module)
            public_attrs = [attr for attr in all_attrs if not attr.startswith("_")]
        except Exception as e:
            print(f"Warning: Could not get dir() for module {name}: {e}", file=sys.stderr)
            public_attrs = []
    
    # Analyze each public attribute
    for attr_name in public_attrs:
        try:
            attr = getattr(module, attr_name)
            
            if inspect.ismodule(attr):
                # Submodule
                if attr.__name__.startswith(name + "."):
                    # Internal submodule - analyze recursively
                    info["submodules"][attr_name] = analyze_module(attr, attr_name, depth + 1, max_depth)
                else:
                    # External module reference
                    info["submodules"][attr_name] = {
                        "name": attr_name,
                        "type": "external_module",
                        "module_name": attr.__name__,
                        "file": safe_getattr(attr, "__file__")
                    }
            elif inspect.isclass(attr):
                if issubclass(attr, Exception):
                    info["exceptions"][attr_name] = analyze_class(attr, attr_name)
                else:
                    info["classes"][attr_name] = analyze_class(attr, attr_name)
            elif inspect.isfunction(attr):
                info["functions"][attr_name] = analyze_function(attr, attr_name)
            elif callable(attr):
                # Callable object (might be builtin function, method, etc.)
                info["functions"][attr_name] = analyze_function(attr, attr_name)
            else:
                # Constant, variable, or other object
                info["constants"][attr_name] = {
                    "name": attr_name,
                    "type": type(attr).__name__,
                    "value": safe_str(attr, 200),
                    "repr": safe_repr(attr, 200),
                    "is_callable": callable(attr),
                    "value_type": str(type(attr))
                }
        except Exception as e:
            # Record inaccessible attributes
            info["constants"][attr_name] = {
                "name": attr_name,
                "type": "inaccessible",
                "error": str(e),
                "is_callable": False
            }
    
    # Add summary statistics
    info["stats"] = {
        "total_classes": len(info["classes"]),
        "total_functions": len(info["functions"]),
        "total_constants": len(info["constants"]),
        "total_submodules": len(info["submodules"]),
        "total_exceptions": len(info["exceptions"]),
        "total_public_attrs": len(public_attrs),
        "has_all_attribute": info["all"] is not None,
        "all_attribute_count": len(info["all"]) if info["all"] else 0
    }
    
    print(f"‚úÖ Module {name} analyzed: {info['stats']['total_classes']} classes, {info['stats']['total_functions']} functions", file=sys.stderr)
    return info

def get_system_info():
    """Get comprehensive system and Python environment information"""
    import platform
    import sys
    
    return {
        "python_version": sys.version,
        "python_version_info": {
            "major": sys.version_info.major,
            "minor": sys.version_info.minor,
            "micro": sys.version_info.micro,
            "releaselevel": sys.version_info.releaselevel,
            "serial": sys.version_info.serial
        },
        "platform": platform.platform(),
        "architecture": platform.architecture(),
        "machine": platform.machine(),
        "processor": platform.processor(),
        "system": platform.system(),
        "python_executable": sys.executable,
        "python_path": sys.path[:10],  # First 10 entries
        "environment_vars": {
            "PYLON_CAMEMU": os.environ.get("PYLON_CAMEMU"),
            "PYTHONPATH": os.environ.get("PYTHONPATH"),
            "PATH": os.environ.get("PATH", "")[:500]  # Truncate PATH
        }
    }

def extract_pypylon_api():
    """Main extraction function for pypylon API"""
    try:
        print("üìä Creating API data structure...", file=sys.stderr)
        api_data = {
            "metadata": {
                "extraction_time": datetime.now().isoformat(),
                "extractor_version": "2.0.0",
                "extraction_type": "comprehensive",
                "system_info": get_system_info()
            },
            "modules": {}
        }
        print("‚úÖ API data structure created", file=sys.stderr)
        
        # Primary modules to analyze
        primary_modules = ["pypylon"]
        
        for module_name in primary_modules:
            try:
                print(f"Importing {module_name}...", file=sys.stderr)
                module = __import__(module_name)
                print(f"Analyzing {module_name}...", file=sys.stderr)
                api_data["modules"][module_name] = analyze_module(module, module_name)
                print(f"Successfully analyzed {module_name}", file=sys.stderr)
                
                # For pypylon, explicitly import and analyze known submodules
                # This ensures consistent analysis regardless of how they're exposed
                if module_name == "pypylon":
                    known_submodules = ["genicam", "pylon", "pylondataprocessing"]
                    for submodule_name in known_submodules:
                        try:
                            print(f"Importing {module_name}.{submodule_name}...", file=sys.stderr)
                            submodule = __import__(f"{module_name}.{submodule_name}", fromlist=[submodule_name])
                            print(f"Analyzing {submodule_name}...", file=sys.stderr)
                            
                            # Add the submodule to the main module's submodules
                            if "submodules" not in api_data["modules"][module_name]:
                                api_data["modules"][module_name]["submodules"] = {}
                            
                            api_data["modules"][module_name]["submodules"][submodule_name] = analyze_module(
                                submodule, submodule_name, depth=1, max_depth=3
                            )
                            print(f"Successfully analyzed {submodule_name}", file=sys.stderr)
                            
                        except ImportError as e:
                            print(f"ImportError for {submodule_name}: {e}", file=sys.stderr)
                            # Add as missing submodule
                            if "submodules" not in api_data["modules"][module_name]:
                                api_data["modules"][module_name]["submodules"] = {}
                            api_data["modules"][module_name]["submodules"][submodule_name] = {
                                "name": submodule_name,
                                "type": "missing_module",
                                "error": str(e),
                                "available": False
                            }
                        except Exception as e:
                            print(f"Error analyzing {submodule_name}: {e}", file=sys.stderr)
                            # Add as error submodule
                            if "submodules" not in api_data["modules"][module_name]:
                                api_data["modules"][module_name]["submodules"] = {}
                            api_data["modules"][module_name]["submodules"][submodule_name] = {
                                "name": submodule_name,
                                "type": "error_module",
                                "error": str(e),
                                "traceback": traceback.format_exc()
                            }
                            
            except ImportError as e:
                print(f"ImportError for {module_name}: {e}", file=sys.stderr)
                api_data["modules"][module_name] = {
                    "name": module_name,
                    "type": "missing_module", 
                    "error": str(e),
                    "available": False
                }
            except Exception as e:
                print(f"Error analyzing {module_name}: {e}", file=sys.stderr)
                api_data["modules"][module_name] = {
                    "name": module_name,
                    "type": "error_module",
                    "error": str(e),
                    "traceback": traceback.format_exc()
                }
        
        # Add global statistics
        print("üìà Computing global statistics...", file=sys.stderr)
        total_classes = 0
        total_functions = 0
        total_methods = 0
        total_properties = 0
        
        def count_module_stats(module_data):
            """Recursively count statistics from a module and its submodules"""
            nonlocal total_classes, total_functions, total_methods, total_properties
            
            if isinstance(module_data, dict) and "stats" in module_data:
                total_classes += module_data["stats"].get("total_classes", 0)
                total_functions += module_data["stats"].get("total_functions", 0)
                
                # Count methods and properties from classes
                for class_data in module_data.get("classes", {}).values():
                    if isinstance(class_data, dict) and "stats" in class_data:
                        total_methods += class_data["stats"].get("total_methods", 0)
                        total_properties += class_data["stats"].get("total_properties", 0)
                
                # Recursively count submodules
                for submodule_data in module_data.get("submodules", {}).values():
                    count_module_stats(submodule_data)
        
        for module_name, module_data in api_data["modules"].items():
            count_module_stats(module_data)
        
        api_data["global_stats"] = {
            "total_modules": len([m for m in api_data["modules"].values() if m.get("type") == "module"]),
            "total_classes": total_classes,
            "total_functions": total_functions,
            "total_methods": total_methods,
            "total_properties": total_properties,
            "total_api_items": total_classes + total_functions + total_methods + total_properties
        }
        print(f"‚úÖ Global stats: {total_classes} classes, {total_functions} functions, {total_methods} methods", file=sys.stderr)
        
        return api_data
        
    except Exception as e:
        print(f"‚ùå Exception in extract_pypylon_api: {e}", file=sys.stderr)
        print(f"   Exception type: {type(e).__name__}", file=sys.stderr)
        return {
            "error": "API extraction failed",
            "message": str(e),
            "type": type(e).__name__,
            "traceback": traceback.format_exc()
        }

# Run the extraction
try:
    print("üöÄ Starting API extraction...", file=sys.stderr)
    result = extract_pypylon_api()
    
    # Check if result contains an error
    if isinstance(result, dict) and "error" in result:
        print(f"‚ùå Extraction returned error: {result['error']}", file=sys.stderr)
        print(json.dumps(result, indent=2, default=str))
        sys.exit(1)
    else:
        print("‚úÖ Extraction completed successfully", file=sys.stderr)
        print(json.dumps(result, indent=2, default=str))
        
except Exception as e:
    print(f"‚ùå Top-level extraction exception: {e}", file=sys.stderr)
    error_result = {
        "error": "Top-level extraction failed",
        "message": str(e),
        "type": type(e).__name__,
        "traceback": traceback.format_exc()
    }
    print(json.dumps(error_result, indent=2, default=str))
    sys.exit(1)
'''

def save_api_dump(api_data: Dict[str, Any], output_file: Path, compress: bool = False) -> None:
    """Save API data to JSON file with integrity verification"""
    
    # Add file metadata
    content = json.dumps(api_data, indent=2, sort_keys=True, default=str)
    
    if "metadata" not in api_data:
        api_data["metadata"] = {}
        
    api_data["metadata"]["file_info"] = {
        "filename": output_file.name,
        "size_bytes": len(content.encode()),
        "compressed": compress,
        "checksum": hashlib.sha256(content.encode()).hexdigest()
    }
    
    # Save file
    if compress:
        import gzip
        output_file_gz = output_file.with_suffix('.json.gz')
        with gzip.open(output_file_gz, 'wt', encoding='utf-8') as f:
            json.dump(api_data, f, indent=2, sort_keys=True, default=str)
        print(f"üíæ Compressed API dump saved to: {output_file_gz}")
    else:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(api_data, f, indent=2, sort_keys=True, default=str)
        print(f"üíæ API dump saved to: {output_file}")


def create_api_dump(python_executable: str = None, 
                   output_file: str = None,
                   compress: bool = False) -> Path:
    """Create comprehensive API dump from pypylon installation"""
    
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"pypylon_api_{timestamp}.json"
    
    output_path = Path(output_file)
    
    print(f"üîç Extracting pypylon API from: {python_executable or 'current environment'}")
    print(f"üìÑ Output: {output_path}")
    
    extractor = PylonAPIExtractor(python_executable)
    api_data = extractor.extract_api()
    
    # Check for extraction errors
    if "error" in api_data:
        raise RuntimeError(f"API extraction failed: {api_data['error']}")
    
    # Add extraction metadata
    if "metadata" not in api_data:
        api_data["metadata"] = {}
    
    api_data["metadata"]["extraction_args"] = {
        "python_executable": python_executable,
        "output_file": str(output_path),
        "compress": compress
    }
    
    save_api_dump(api_data, output_path, compress)
    
    # Print summary statistics
    global_stats = api_data.get("global_stats", {})
    print(f"\nüìä API Analysis Summary:")
    print(f"   üì¶ Modules: {global_stats.get('total_modules', 0)}")
    print(f"   üèõÔ∏è  Classes: {global_stats.get('total_classes', 0)}")
    print(f"   üîß Functions: {global_stats.get('total_functions', 0)}")
    print(f"   ‚öôÔ∏è  Methods: {global_stats.get('total_methods', 0)}")
    print(f"   üè∑Ô∏è  Properties: {global_stats.get('total_properties', 0)}")
    print(f"   üìà Total API items: {global_stats.get('total_api_items', 0)}")
    
    return output_path


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="Extract comprehensive pypylon API information",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Extract from current environment
  python pypylon_api_dumper.py --output pypylon_v4.2.0.json
  
  # Extract from specific Python environment
  python pypylon_api_dumper.py --python-env ~/.pyenv/versions/3.11.0/bin/python --output pypylon_stable.json
  
  # Extract with compression
  python pypylon_api_dumper.py --output pypylon_api.json --compress
  
  # Extract to timestamped file
  python pypylon_api_dumper.py
        """
    )
    
    parser.add_argument(
        "--python-env",
        help="Python executable to use for extraction (default: current environment)"
    )
    parser.add_argument(
        "--output", "-o",
        help="Output JSON file path (default: timestamped filename)"
    )
    parser.add_argument(
        "--compress",
        action="store_true",
        help="Compress output with gzip"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Enable verbose output"
    )
    
    args = parser.parse_args()
    
    try:
        api_file = create_api_dump(
            python_executable=args.python_env,
            output_file=args.output,
            compress=args.compress
        )
        
        print(f"\n‚úÖ API extraction completed successfully!")
        print(f"üìã Use this file for API compatibility checking")
        
    except Exception as e:
        print(f"‚ùå Error creating API dump: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 